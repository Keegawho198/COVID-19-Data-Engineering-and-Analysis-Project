{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Data Engineering and Analysis Project\n",
    "\n",
    "This project focuses on analyzing COVID-19 data to extract meaningful insights using ETL processes and data engineering techniques.\n",
    "\n",
    "## Introduction\n",
    "This project provides detailed insights into the pandemic period, leveraging comprehensive data analysis techniques to highlight significant trends and patterns in COVID-19 cases and deaths worldwide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "Import all relevant dependencies for the project,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pyarrow as pa\n",
    "import pyarrow.csv as pv_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract COVID-19 Data\n",
    "Reading in the datasets for countries and COVID-19 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Load the CSV file into a DataFrame\n",
    "countries_dataset_path = \"Resources/countries.csv\"\n",
    "countries_dataset = pd.read_csv(countries_dataset_path)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "countries_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Load the CSV file into a DataFrame\n",
    "covid_cases_dataset_path = \"Resources/WHO COVID-19 cases.csv\"\n",
    "covid_cases_dataset = pd.read_csv(covid_cases_dataset_path)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "covid_cases_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-driven Interaction\n",
    "Filter data based on date, country, or WHO region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_csv_data(df):\n",
    "    print(\"Select a filter:\")\n",
    "    print(\"1. Filter by Date\")\n",
    "    print(\"2. Filter by Country\")\n",
    "    print(\"3. Filter by WHO_region\")\n",
    "    print(\"4. No filter (Load all data)\")\n",
    "\n",
    "    filter_option = input(\"Enter the number corresponding to your filter choice: \")\n",
    "\n",
    "    df = covid_cases_dataset\n",
    "\n",
    "    # Apply filters based on user selection\n",
    "    if filter_option == '1':\n",
    "        start_date = input(\"Enter start date (YYYY-MM-DD): \")\n",
    "        end_date = input(\"Enter end date (YYYY-MM-DD): \")\n",
    "        df['Date_reported'] = pd.to_datetime(df['Date_reported'])\n",
    "        df = df[(df['Date_reported'] >= start_date) & (df['Date_reported'] <= end_date)]\n",
    "    elif filter_option == '2':\n",
    "        country = input(\"Enter country to filter by: \")\n",
    "        df = df[df['Country'] == country]\n",
    "    elif filter_option == '3':\n",
    "        who = input(\"Enter your desired WHO Region: \").upper()\n",
    "        df = df[df['WHO_region'] == who]\n",
    "    elif filter_option == '4':\n",
    "        print(\"No filter applied.\")\n",
    "    else:\n",
    "        print(\"Invalid option.\")\n",
    "    \n",
    "    # Perform further ETL processes on filtered data\n",
    "    return df\n",
    "\n",
    "filtered_data = filter_csv_data(covid_cases_dataset)\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation and Cleaning\n",
    "Renaming columns, merging datasets, handling missing and duplicate data, and adjusting data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for merging\n",
    "countries_dataset = countries_dataset.rename(columns={'country': 'Country Code', 'name': 'Country'})\n",
    "covid_cases_dataset = covid_cases_dataset.rename(columns={\n",
    "    'Date_reported': 'Date',\n",
    "    'Country_code': 'Country Code',\n",
    "    'Country': 'Country',\n",
    "    'WHO_region': 'WHO Region',\n",
    "    'New_cases': 'New Cases',\n",
    "    'Cumulative_cases': 'Cumulative Cases',\n",
    "    'New_deaths': 'New Deaths',\n",
    "    'Cumulative_deaths': 'Cumulative Deaths'\n",
    "})\n",
    "\n",
    "# Merge datasets to create the COVID-19 Dataset\n",
    "complete_dataset_raw = pd.merge(covid_cases_dataset, countries_dataset, on=\"Country Code\", how='outer')\n",
    "complete_dataset_raw = complete_dataset_raw.drop(columns=[\"Country_y\"]).rename(columns={\n",
    "    \"Country_x\": \"Country\",\n",
    "    \"latitude\": \"Latitude\",\n",
    "    \"longitude\": \"Longitude\"\n",
    "})\n",
    "complete_dataset_raw['id'] = range(1, len(complete_dataset_raw) + 1)\n",
    "columns = ['id'] + [col for col in complete_dataset_raw.columns if col != 'id']\n",
    "complete_dataset_raw = complete_dataset_raw[columns]\n",
    "complete_dataset_raw = complete_dataset_raw.dropna().drop_duplicates(subset=['Date', 'Country'])\n",
    "complete_dataset_raw['Date'] = pd.to_datetime(complete_dataset_raw['Date'])\n",
    "LngLatdataset = complete_dataset_raw.copy()\n",
    "\n",
    "# Create 'Case ID' before dropping columns\n",
    "complete_dataset_raw['Case ID'] = complete_dataset_raw['Country Code'] + complete_dataset_raw['id'].astype(str)\n",
    "\n",
    "# Add 'Coordinates' column\n",
    "complete_dataset_raw['Coordinates'] = complete_dataset_raw.apply(lambda row: f\"({row['Latitude']}, {row['Longitude']})\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "complete_dataset_cleaned = complete_dataset_raw.drop(columns=['Longitude', 'Latitude'])\n",
    "\n",
    "# Ensure all columns have spaces instead of underscores\n",
    "complete_dataset_cleaned.columns = complete_dataset_cleaned.columns.str.replace('_', ' ')\n",
    "\n",
    "# Reorder the columns to match the desired order\n",
    "desired_order = ['id', 'Date', 'Country Code', 'Country', 'Continent', 'WHO Region', 'New Cases', 'Cumulative Cases', 'New Deaths', 'Cumulative Deaths', 'Coordinates', 'Case ID']\n",
    "complete_dataset_cleaned = complete_dataset_cleaned[desired_order]\n",
    "\n",
    "# Check results\n",
    "complete_dataset_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries DataFrame\n",
    "Creating and exporting a DataFrame for country codes and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Save the Countries DataFrame. Remove duplicates based on 'Country Code'\n",
    "Countries_df = complete_dataset_cleaned[['Country Code', 'Country']].drop_duplicates(subset=['Country Code']).reset_index(drop=True)\n",
    "Countries_df.to_csv('COVID-19-ETL-Outputs/Countries.csv', index=False)\n",
    "print(\"Countries DataFrame saved as 'Countries.csv'\")\n",
    "Countries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates DataFrame\n",
    "Creating and exporting a DataFrame for country coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-numeric values from Latitude and Longitude\n",
    "LngLatdataset = complete_dataset_raw[\n",
    "    complete_dataset_raw['Latitude'].apply(lambda x: pd.to_numeric(x, errors='coerce')).notnull() &\n",
    "    complete_dataset_raw['Longitude'].apply(lambda x: pd.to_numeric(x, errors='coerce')).notnull()\n",
    "]\n",
    "\n",
    "# Convert Latitude and Longitude to numeric\n",
    "LngLatdataset['Latitude'] = pd.to_numeric(LngLatdataset['Latitude'])\n",
    "LngLatdataset['Longitude'] = pd.to_numeric(LngLatdataset['Longitude'])\n",
    "\n",
    "# Create Coordinates DataFrame\n",
    "Coordinates_df = LngLatdataset[['Country Code', 'Latitude', 'Longitude', 'Coordinates']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Save the Coordinates DataFrame as CSV\n",
    "Coordinates_csv_path = 'COVID-19-ETL-Outputs/Coordinates.csv'\n",
    "Coordinates_df.to_csv(Coordinates_csv_path, index=False)\n",
    "\n",
    "# Convert the Coordinates_df DataFrame to a PyArrow Table\n",
    "coordinates_df_table = pa.Table.from_pandas(Coordinates_df)\n",
    "with open('COVID-19-ETL-Outputs/Coordinates.csv', 'wb') as f:\n",
    "    pv_csv.write_csv(coordinates_df_table, f)\n",
    "\n",
    "print(\"Coordinates DataFrame saved as 'Coordinates.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID-19 Dataset\n",
    "Creating and Saving the COVID-19_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned and renamed COVID-19 Dataset\n",
    "complete_dataset_cleaned.to_csv('COVID-19-ETL-Outputs/COVID-19_Dataset.csv', index=False)\n",
    "print(\"COVID-19 Dataset saved as 'COVID-19_Dataset.csv'\")\n",
    "complete_dataset_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient Database\n",
    "Creating and exporting a DataFrame for all COVID-19 cases and deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Save the Patient Database DataFrame\n",
    "Patient_Database = pd.DataFrame({\n",
    "    'Case ID': complete_dataset_cleaned['Case ID'].astype(str),\n",
    "    'Date': complete_dataset_cleaned['Date'],\n",
    "    'Country Code': complete_dataset_cleaned['Country Code'],\n",
    "    'New Cases': complete_dataset_cleaned['New Cases'],\n",
    "    'Cumulative Cases': complete_dataset_cleaned['Cumulative Cases'],\n",
    "    'New Deaths': complete_dataset_cleaned['New Deaths'],\n",
    "    'Cumulative Deaths': complete_dataset_cleaned['Cumulative Deaths']\n",
    "})\n",
    "Patient_Database = Patient_Database.dropna(how='any')\n",
    "Patient_Database.to_csv('COVID-19-ETL-Outputs/Patient_Database.csv', index=False)\n",
    "print(\"Patient Database DataFrame saved as 'Patient_Database.csv'\")\n",
    "Patient_Database.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Analysis\n",
    "- Group by Country\n",
    "- Global Aggregation\n",
    "- Correlation Analysis\n",
    "\n",
    "Performing grouped analysis, correlation analysis, and saving the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Country and Aggregate Data\n",
    "country_group_data = complete_dataset_cleaned.groupby('Country').agg({\n",
    "    'New Cases': ['sum', 'mean', 'std'],\n",
    "    'New Deaths': ['sum', 'mean', 'std']\n",
    "}).rename(columns={'New Cases': 'Aggregate Recent Diagnosis', 'New Deaths': 'Aggregate Recent Fatalities'})\n",
    "country_group_data.to_csv('COVID-19-ETL-Outputs/Aggregated_country_statistics.csv', index=False)\n",
    "\n",
    "# Check the Grouped Data\n",
    "country_group_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "correlation = complete_dataset_cleaned[['New Cases', 'New Deaths', 'Cumulative Cases', 'Cumulative Deaths']].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('COVID-19-ETL-Outputs/correlation_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Statistics & Analysis\n",
    "- Aggregating and analyzing global maximum and minimum cases and deaths.\n",
    "\n",
    "The analysis reveals that the country with the highest number of cases and deaths was the United States of America, demonstrating the severe impact of the pandemic in that region. Conversely, the country with the fewest COVID-19 cases was Montserrat, while Nauru recorded the lowest number of deaths globally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation to find the max, min cases and deaths all over the world\n",
    "country_stats = complete_dataset_cleaned.groupby('Country').agg({\n",
    "    'Cumulative Cases': 'max',\n",
    "    'Cumulative Deaths': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "# Find the country with maximum cases\n",
    "max_cases_country = country_stats.loc[country_stats['Cumulative Cases'].idxmax()]\n",
    "\n",
    "# Find the country with minimum cases\n",
    "min_cases_country = country_stats.loc[country_stats['Cumulative Cases'].idxmin()]\n",
    "\n",
    "# Find the country with maximum deaths\n",
    "max_deaths_country = country_stats.loc[country_stats['Cumulative Deaths'].idxmax()]\n",
    "\n",
    "# Find the country with minimum deaths\n",
    "min_deaths_country = country_stats.loc[country_stats['Cumulative Deaths'].idxmin()]\n",
    "\n",
    "# Display Results\n",
    "print(\"Country with Maximum Cases:\", max_cases_country)\n",
    "print(\"\\nCountry with Minimum Cases:\", min_cases_country)\n",
    "print(\"\\nCountry with Maximum Deaths:\", max_deaths_country)\n",
    "print(\"\\nCountry with Minimum Deaths:\", min_deaths_country)\n",
    "\n",
    "# Save the results to a text file using PyArrow\n",
    "with pa.BufferOutputStream() as buffer:\n",
    "    buffer.write(f\"Country with Maximum Cases: {max_cases_country}\\n\".encode())\n",
    "    buffer.write(f\"\\nCountry with Minimum Cases: {min_cases_country}\\n\".encode())\n",
    "    buffer.write(f\"\\nCountry with Maximum Deaths: {max_deaths_country}\\n\".encode())\n",
    "    buffer.write(f\"\\nCountry with Minimum Deaths: {min_deaths_country}\\n\".encode())\n",
    "    result = buffer.getvalue()\n",
    "\n",
    "with open('COVID-19-ETL-Outputs/Global_statistics.txt', 'wb') as file:\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Statistics (Australian Data Analysis)\n",
    "- Filtering Australian Data\n",
    "- Calculating Key Metrics\n",
    "- Summarize Data With Pivot Table\n",
    "\n",
    "A focused analysis on Australia showcases the country’s pandemic trends. The findings highlight the total average new cases and identify the peak daily cases and deaths in Australia, providing a clear understanding of the pandemic’s progression in the region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Australian Data\n",
    "Filter the data to Australia for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by country Australia\n",
    "australia_data = complete_dataset_cleaned[complete_dataset_cleaned['Country'] == 'Australia']\n",
    "australia_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Key Metrics for Australia\n",
    "Finding the average new cases, maximum and minimum cases, and deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average new cases in total in Australia\n",
    "average_cases = australia_data['New Cases'].mean()\n",
    "print(f\"Average COVID-19 cases in Australia: {average_cases:.2f}\")\n",
    "\n",
    "# Find the day with maximum cases\n",
    "max_cases_day = australia_data.loc[australia_data['New Cases'].idxmax()]\n",
    "print(f\"Maximum cases: {max_cases_day['New Cases']} on {max_cases_day['Date'].date()}\")\n",
    "\n",
    "# Find the day with minimum cases\n",
    "min_cases_day = australia_data.loc[australia_data['New Cases'].idxmin()]\n",
    "print(f\"Minimum cases: {min_cases_day['New Cases']} on {min_cases_day['Date'].date()}\")\n",
    "\n",
    "# Find the day with maximum deaths\n",
    "max_deaths_day = australia_data.loc[australia_data['New Deaths'].idxmax()]\n",
    "print(f\"Maximum deaths: {max_deaths_day['New Deaths']} on {max_deaths_day['Date'].date()}\")\n",
    "\n",
    "# Find the day with minimum deaths\n",
    "min_deaths_day = australia_data.loc[australia_data['New Deaths'].idxmin()]\n",
    "print(f\"Minimum deaths: {min_deaths_day['New Deaths']} on {min_deaths_day['Date'].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Local Statistics for Australia\n",
    "Using PyArrow to save Australian statistics to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result to a text file using PyArrow\n",
    "with pa.BufferOutputStream() as buffer:\n",
    "    buffer.write(f\"Average COVID-19 cases in Australia: {average_cases:.2f}\\n\".encode())\n",
    "    buffer.write(f\"\\nMaximum cases in Australia: {max_cases_day['New Cases']} on {max_cases_day['Date'].date()}\\n\".encode())\n",
    "    buffer.write(f\"\\nMinimum cases in Australia: {min_cases_day['New Cases']} on {min_cases_day['Date'].date()}\\n\".encode())\n",
    "    buffer.write(f\"\\nMaximum deaths in Australia: {max_deaths_day['New Deaths']} on {max_deaths_day['Date'].date()}\\n\".encode())\n",
    "    buffer.write(f\"\\nMinimum deaths in Australia: {min_deaths_day['New Deaths']} on {min_deaths_day['Date'].date()}\\n\".encode())\n",
    "    result = buffer.getvalue()\n",
    "\n",
    "with open('COVID-19-ETL-Outputs/Australian_statistics.txt', 'wb') as file:\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Table Summary\n",
    "Summarizing Australian data with a pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pivot_table() to summarize the data\n",
    "pivot_summary = australia_data.pivot_table(\n",
    "    index='Date', values=['New Cases', 'New Deaths'], aggfunc='sum'\n",
    ")\n",
    "\n",
    "# Convert the summarized values to integers\n",
    "pivot_summary = pivot_summary.astype(int)\n",
    "\n",
    "# Display the pivot summary\n",
    "pivot_summary\n",
    "\n",
    "# Export the Detailed Covid Analysis\n",
    "pivot_summary.to_csv('COVID-19-ETL-Outputs/Pivot_summary.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Pivot Table Summary\n",
    "Creating a line plot to visualize new cases and deaths over time in Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting pivot table summary with dual y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plotting new cases on the primary y-axis\n",
    "ax1.plot(pivot_summary.index, pivot_summary['New Cases'], label='New Cases', color='b')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('New Cases', color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Creating a secondary y-axis for new deaths\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(pivot_summary.index, pivot_summary['New Deaths'], label='New Deaths', color='r')\n",
    "ax2.set_ylabel('New Deaths', color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Enhancing the plot\n",
    "plt.title('New Cases and Deaths Over Time in Australia')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('COVID-19-ETL-Outputs/Pivot_Summary_Plot.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
